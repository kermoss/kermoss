= Getting Started
== Prerequisites

Kermoss Framework runs on Java 8 and above, and also uses the following direct dependencies:

* spring-boot version 2.2.4 and above
* spring data jpa
* spring kafka
* spring cloud openfeign

Regarding databases, kermoss is tested with oracle, postgresql and mysql

== Getting Kermoss

To be able to use kermoss in your project, add the following dependency in your pom.xml
====
[source,xml]
----
<dependency>
    <groupId>io.kermoss</groupId>
    <artifactId>reactive-business-flow</artifactId>
    <version>${io.kermoss.version}</version>
</dependency>
----
====

== Connect kermoss to your database   

Kermoss uses ** Liquibase ** (an open source database change management tool) to manage the versioning of its database schema, if you already have liquibase in your project, you just have to add only this line to your db.changelog-master.xml file

[source,xml]
----
<include file="db/changelog/db-kermoss-master.xml" relativeToChangelogFile="false"/>
---- 
If your project does not include the ** liquibase ** tool, in this case add the following configuration in your pom.xml in the section menu:build[plugins]

====
[source,xml]
----
<plugin>
  <groupId>org.liquibase</groupId>
   <artifactId>liquibase-maven-plugin</artifactId>
   <configuration>
	<propertyFile>src/main/resources/liquibase.properties</propertyFile> <1>
	</configuration>
</plugin>
----
<1> create the liquibase.properties file in the menu:src[main>resources] location with the following elements:

[source, properties]
----
url=jdbc:postgresql://localhost:5432/pizzashop <1>
username=postgres <2>
password=mysecretpassword <3>
driver=org.postgresql.Driver <4>
changeLogFile=db/changelog/db.changelog-master.xml <5>
----
for (1)-(2)-(3)-(4) change them with those of your own database .

for (5) create db.changelog-master.xml file in the menu:src[main>resources>db>changelog] folder in your project with the following content:

[source, xml]
----
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<databaseChangeLog xmlns="http://www.liquibase.org/xml/ns/dbchangelog" xmlns:ext="http://www.liquibase.org/xml/ns/dbchangelog-ext" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.liquibase.org/xml/ns/dbchangelog-ext http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-ext.xsd http://www.liquibase.org/xml/ns/dbchangelog http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-3.4.xsd">
    <include file="db/changelog/db-kermoss-master.xml" relativeToChangelogFile="false"/>
</databaseChangeLog>
----
it's almost finished, run the maven command to import the kermoss schema into your database:

[source, shell]
----
mvn process-resources liquibase:update
----     
====

Normally Kermoss should integrate into your project with your existing dataSource and transactionManager configuration with no worries.

If you have not yet configured your dataSource , put this configuration in your application.yml file, the database we took as an example is postgresql (oracle or mysql are also supported)

====
[source,yaml]
----
spring.datasource:
  url: jdbc:postgresql://localhost:5432/pizzashop
  username: postgres
  password: mysecretpassword
  driver-class-name: org.postgresql.Driver
  hikari: <1>
    maximum-pool-size: 10


# Hibernate settings
spring.jpa.show-sql: true <2>
spring.jpa.properties.hibernate.dialect: org.hibernate.dialect.PostgreSQLDialect
spring.jpa.properties.hibernate.hbm2ddl.auto: validate <3>
----
<1> kermoss uses hikari pool by default, there is no restriction to choose for example tomcat or c3p0 as connection pool
<2> For debugging sql queries .
<3> We recommend setting this value to ** validate ** for the production environment    
====

== Basic configuration concepts

this part indicates the first concepts to start kermoss within your project, it illustrates the basic and fundamental elements to configure your development or test environment.
====
[source,yaml]
----
kermoss: <1>
  service-name: pizza-shop <2>
  transport:
    default-layer: http <3>
    sources:
      market-service: <4>
          http: http://localhost:8081/command-executor/commands <5>
      shippement-service:
           http: http://localhost:8081/command-executor/commands
      pizza-shop: 
           http: http://localhost:8081/command-executor/commands
----
<1> this is the root of the kermoss properties, at this level you can explore all the properties to configure using the auto-completion of your IDE
<2> the name of your microservice or application is used to improve the audit and the level of command tracking, if you omit this option the name of the application of your project will be taken into account.
<3> possible values ‚Äã‚Äãare: kafka, feign, and http
<4> the destination key configured at the command level
<5> the target address to which kermoss will send the command based on the destination key    
====
 
== First steps to master Kermoss

To concretely master the different concepts of kermoss we will refer to the pizzashop example, for more details on the source code of the pizzashop project see https://github.com/kermoss/kermoss/tree/master/saga-worker[here]

The pizzashop project consists of three microservices:

* pizzashop: contains the logic for ordering pizza, cooking, and payment
* pizzaship: contains the delivery logic
* market: provides the necessary ingredients for a pizza

== How to run pizza shop microservices

====
[source, shell]

git clone https://github.com/kermoss/kermoss.git
cd kermoss
mvn clean install <1>
cd saga-worker/target
java -jar saga-worker-${version}.jar --spring.profiles.active=dev,shop <2>
java -jar saga-worker-${version}.jar --spring.profiles.active=dev,ship <3>
java -jar saga-worker-${version}.jar --spring.profiles.active=dev,market <4>

<1> This will build the whole project and include saga-worker which the maven module containing the source code for the pizza shop microservices 
<2> launch the pizzshop microservice in dev mode
<3> launch the pizzaship microservice in dev mode
<4> launche the microservice market in dev mode

_Each microservice has its own configuration file you can find and modify it in the saga-worker / resources folder example application-market.yml is the configuration file for market microservice_  
====

If all goes well without error, this entry point **http://localhost:8081/pizza/test/order** allows you to run the pizza order scenario.

== How to run pizza shop as single monolith application
====
[source,shell]
----
java -jar saga-worker-${version}.jar --spring.profiles.active=dev,single <1>
----
<1> launch the pizzshop application in dev mode

_application-single.yml est le fichier de configuration yaml pour pizza shop application_   
====

== BFM & pizzashop together üôè

[NOTE]
====
Kermoss by default uses communication in asynchronous mode even if the pizzaship service is not available it can continue while waiting for it to be up and running, but this does not prevent kermoss from also supporting synchronous communication in blocking mode, this will be illustrated in the scenario when pizzashop microservice requests the service market in blocking mode, if there is not enough ingredient or the service does not respond, the pizzashope service stops the global transaction    
====

The pizza shop microservice is the owner and initiator of the global transaction, so by default kermoss assigns it the role of the orchestrator of the entire distributed transaction cycle, all communication in the BFM (Business Flow Model) internally in pizza shop are driven by events, on the other hand communication with other microservices (market and pizza ship) are driven by commands


[TIP]
====
A BFM (Business Flow Model) is just a set of components in the form of a java class called ** workers ** (global and local transaction)

.A BFM is made up of :

* ** worker ** class that extends GlobalTransactionWorker allowing to start or close a global transaction by listening on events..
* ** worker ** class that extends LocalTransactionWorker allowing to start or close or rollback (compensate) a local transaction by listening on events.
* Each ** worker ** communicate internally by events and can send commands to remote BFMs all this happens through a chain of operators ** TransactionStepDefinition ** these are in a way the equivalent of RouteBuilder in the camel project.    
====

== Kermoss : project organization

it is better to have the following organization for your project, however you are free to choose a suitable structure for your project, the objective of this part is to show you the different components that you would need to develop your project with kermoss.   

----
üìí pizza-shop <1>
  üìÑ pom.xml
  üìÇ src/main/java
    üìÇ org.pizzasho <2>
      üìÇ api <3>
      üìÇ cmd <4>
      üìÇ decoder <5>
      üìÇ domain <6>
      üìÇ event <7>
      üìÇ exception <8>
      üìÇ service <9>
      üìÇ worker <10>
        üìÑ OrderPizzaStateWorker.java <11>
  üìÇ src/main/resources
    üìÑ application.yml <12>  
----
<1> your project root
<2> your root package: the domain name
<3> you can create your rest api here
<4> package containing the commands to send to remote BFMs
<5> package contains decoder services; when a command lands in a remote microservice, the decoder service creates an event based on the commands subject (a subject is only a key that allows the mapping with an event), for this purpose a given worker (global or local transaction) receives this command by listening on this event.   
<6> your domain business logic (model + repositories + services)
<7> package containing the events for internal communication between the different workers (Global and Local transaction)
<8> package containing exceptions
<9> package containing the services of the application layer
<10> package containing the BFM as a component, we recommend that worker adhere to the following convention: <serviceName>Worker.java
<11> contains the configuration of kermoss as well as your application

== Create your first globalTransaction worker

You just have to create a java class like OrderPizzaStateWorker.java (see the example of pizzashop) which extends GlobalTransactionWorker and annotate it with spring @Component annotation

====
[source, java, linenums]
----
@Component
public class OrderPizzaStateWorker extends GlobalTransactionWorker<OrderPizzaReceivedEvent, OrderPizzaReadyEvent> {
    
    public OrderPizzaStateWorker() {
        super(new WorkerMeta("OrderPizzaService")); <1>
    }

    @Override
    @BusinessGlobalTransactional <2>
    public GlobalTransactionStepDefinition onStart(OrderPizzaReceivedEvent orderPizzaReceivedEvent)  { <3>
        return GlobalTransactionStepDefinition.builder() <4>
                .in(orderPizzaReceivedEvent)<5>
                .meta(this.meta)<6>
                .process(Optional.empty())<7>
                .blow(Stream.of(new OrderPizzaReadyEvent(orderPizzaReceivedEvent.getCartId())))<8>
                .build();
    }

    @Override
    @CommitBusinessGlobalTransactional <9>
    public GlobalTransactionStepDefinition onComplete(OrderPizzaReadyEvent orderPizzaReadyEvent ) { <10>
        return GlobalTransactionStepDefinition.builder()
                .in(orderPizzaReadyEvent)
                .meta(this.meta)
                .process(Optional.empty())
                .build();
    }
}
----
<1> Worker Meta data, contains the unique name of the global Transaction, it allows to identify it, and to attach the different local transaction workers that must be subordinated by this transaction
<2> Transaction Demarcation: start a new global transaction by listening to an event
<3> listen on an event of type OrderPizzaReceivedEvent
<4> Create a Global Transaction StepDefinition it is the equivalent of a route builder it allows to execute a command chain
<5> allow the Global Transaction StepDefinition to consume the event
<6> pass the meta data reference to the Global Transaction StepDefinition
<7> you can put a side effect here
<8> trigger an event stream
<9> Transaction Demarcation: Commit and close Global Transaction by listening to an event
<10> listen on an event of type orderPizzaReadyEvent
====

== Begin a new Global transaction

To be able to start a new global transaction, start an event with:

====
[source, java ,linenums]
----
@Autowired <1>
ApplicationEventPublisher applicationEventPublisher;

@Transactional <2>
    public void prepareOrder(Cart cart){
        orders.put(cart.getId(), cart);
        applicationEventPublisher.publishEvent(new OrderPizzaReceivedEvent(cart.getId()));<3>
    }
----
<1> inject a spring ApplicationEventPublisher to publish en event
<2> decorate your method with the classic ** @ Transactional ** annotation from spring
<3> publish your event to start the global transaction   
====

== Bind a global transaction context

Supposing that in some situation you want to launch an event from your business logic to call a worker (ex: play, commit, or rollback a localTransaction), in this case you need a way to attach the context of a global transaction, by persisting its id in your business model at this level you can communicate with your BFM, outside the context of the global transaction

Kermoss provides this feature by offering the attach method in the pipeline ** GlobalTransactionStepDefinition ** or ** LocalTransactionStepDefinition ** in this case you can bind a global transaction context either from GlobalTransaction worker, or LocalTransaction Worker.

[source,java]
----
       return GlobalTransactionStepDefinition.builder()
                ...
                .attach(gtx ->orderSevice.saveGlobalTransactionId(gtx)) <1>
                .build();
    }
----
 
== Call your BFM workers from outside  

You can call your BFM at all levels from your business logic by injecting the BusinessFlow component of the kermoss framework into your services then call the ** access ** method
      
[source,java]
----
@Service
public class BakingService {

    @Autowired
    BusinessFlow businessFlow; <1>
    	
    private static final Logger log = LoggerFactory.getLogger(BakingService.class);
    @Transactional <2>
    public void bake(String gtx, String cartid){
        businessFlow.access(gtx, new BakingPizzaReadyEvent(cartid));	<3>
    }
}
----
<1> inject a kermoss ** BusinessFlow ** service
<2> wrap your business logic with the classic spring annoation ** @ Transactional **, to ensure that your business logic is transactional including BFM 
<3> call the access method by injecting it with a global transaction id already persisted in your business model, then the second parameter used as event to commit the local transaction ** BakerPizzaServiceWorker ** in the pizzashop microservice

== Send a command To a remote BFM

Sending a command to a remote BFM is quite simple with kermoss, just create a class that extends BaseTransactionCommand and choose a convinient string **_subject_** which would later be used by the remote BFM's decoder service to create an event (kermoss will publish this event to the various subscribers in the BFM in order to receive this command). The second important argument is  **_destination_** key parameter that you will then map it with an target address (HTTP, or a Kafka topic) depending on the transport layer of your preference.
 
Finally you can call the ** send ** operator of the ** TransactionStepDefinition ** pipeline allowing to send a command stream either from a global or a local transaction.
 
====
[source,java]
----

@Override
    @SwitchBusinessLocalTransactional
    public LocalTransactionStepDefinition onNext(BoxDeliverFinishedEvent onNextEvent) {
       String invoiceRef="5b6a668c-152a-44b4-8fbd-8819bc63aebb"; 
    	PayBillCommand cmd = new PayBillCommand("pay-delivery-service", "",new Bill(1, invoiceRef)
                , "pizza-shop"); <1>
        return LocalTransactionStepDefinition.builder()
                .in(onNextEvent)
                .blow(Stream.of(new BoxDelivredEvent()))<2>
                .meta(this.meta)
                .send(Stream.of(cmd)) <3>
                .build();
    }

----
<1> pizzaship microservice configure the PayBillCommand command with the **destination** key **pizza-shop** to send it to the pizzashop microservice & ** subject ** key **"pay-delivery-service"** to trigger an event by the decoder service of the remote BFM 
<2> triggers the BoxDelivredEvent
<3> the operator **send(Stream.of(cmd))** is used to send the PayBillCommand command
    
====

=== Map a command's subject with a target address

Kermoss routes the commands to the remote BFMs based on their destination key, the destination key must be mapped with an address (HTTP or service name in consul or eurika registry services, kafka topic) in your configuration file.
====
[source, yaml]
----
kermoss: 
  service-name: pizza-shop
  transport: 
    default-layer: http <1>
  sources: 
    shippement-service: <2>
      feign: shippement-service <3>
      http: "http://localhost:8083/command-executor/command" <4>
      kafka: io.kermoss.topics.pizzashop.shippementservice <5>
----
<1> choose your suitable transport layer; the possible values ‚Äã‚Äãare: kafka for the kafka broker, or if you prefer the HTTP transport layer, use feign or http
<2> this is the subject key of the commad to map to a target address
<3> if the ** feign ** option is chosen as a value for the ** transport.default-layer ** property, the ** "shippement-service" ** value of the ** feign ** key should match the service name of the microservice (pizza ship) in your service catalog (eurika, consul)
<4> use the "http" key mapped to an http address of the "pizza ship" microservice if only if the ** http ** option is chosen as a value for the ** transport.default-layer ** property, the following path "/ command-executor / command" must be included in your http url
<5> the value of the kafka key matches the name of the kafka topic if only if the ** kafka ** option is configured as a value for the ** transport.default-layer ** property.
====

[TIP]
====
.transport.default-layer property:
* We recommend that you adopt the feign option if your choice of transport layer will be HTTP and you later want to deploy your microservice with kermoss in a production environment.
* Use http option in your test or development environment, or if you do not have a registry service
====

== Receive a command from a remote BFM
if you have opted for kafka to be the default transport layer for your project, in this case it will be necessary to add this following configuration part in your yaml or properties file: 
====
[source, yaml]
----
kermoss: 
  service-name: pizza-shop
  transport: 
    default-layer: kafka
  sinks: <1>
    pizza-shop: 
      kafka: io.kermoss.topics.pizzashop <2>

----
<1> sinks: wraps all the possible topics to consume, as a source of commands for your BFM
<2> tells kermoss if you have chosen the kafka value for the transport.default-layer property to consume the commands coming from the topic ** io.kermoss.topics.pizzashop **
 
====

As already explained previously, when a command lands on your microservice, it is necessary to trigger an event indicating to the BFM that there is a new command waiting in the pool to be consumed by workers that subscribe to this event.
to carry out this operation you should create a decoder service allowing to produce this event.

====
[source, java]
----
public class DeliverPizzaDecoder implements BaseDecoder {

    @Override
    public BaseTransactionEvent decode(CommandMeta meta) { <1>
        BoxArrivedEvent deliverPizzaStartedEvent = new BoxArrivedEvent();<2>
        return deliverPizzaStartedEvent;
    }
}
----
<1> contains the mata data on the command
<2> produce an event and then drop it off by kermoss on an event bus, so workers who subscribe to this type of event can consume the command     
====

=== How to configure the decoder service

So that your ** decoder service ** is able to produce an event when a command arrives, it is necessary to register it and map it with the subject of the command in a dedicated component for the configuration, see the code java below .

====
[source, java]
----
@Configuration
public class DecoderConfiguration extends DecoderRegistry { <1>

    @PostConstruct
    public void setup() {
        DeliverPizzaDecoder decoder1 = new DeliverPizzaDecoder();
        this.put("deliver-pizza", decoder1); <2>
        
    }
}
----
<1> here you can put all the mapping of your decoder services in your microservice
<2> "deliver-pizza" subject mapping with the DeliverPizzaDecoder
====

=== Commands consumption
 
In the end, the command becomes visible and ready to be consumed by all the workers of your BFM who are subscribed to the BoxArrivedEvent event

====
[source, java]
----
public class DeliverBoxWorker extends GlobalTransactionWorker<BoxArrivedEvent, BoxDelivredEvent> { 
 @Override
    @BusinessGlobalTransactional
    public GlobalTransactionStepDefinition onStart(BoxArrivedEvent boxArrivedEvent){ <1>
        return GlobalTransactionStepDefinition.builder()
                .in(boxArrivedEvent)
                .meta(this.meta)
                .receive(ToDilever.class, x -> System.out.println(x.toString())) <2>
                .build();
    }
 ...   
}
---- 
<1> subscribe to the ** boxArrivedEvent ** event produced by the decoder Service ** DeliverPizzaDecoder **
<2> consumption of the command : ToDilever  
====

== Enlist a Local Transaction Worker

the creation and the enrollment of a local transaction is very similar to a global transaction, indeed to create a local transaction it is enough just to extend the class ** LocalTransactionWorker ** and to annotate it with @component so that it is supported by kermoss, we can take as an example the ChefCookingServiceWorker.java class in the pizzashop microservice.
====
[source, java]
----
package io.kermoss.saga.pizzashop.worker;

@Component
public class ChefCookingServiceWorker
		extends LocalTransactionWorker<OrderPizzaPendingEvent, OrderPizzaCookedEvent, ErrorLocalOccured> {

	@Autowired
	PizzaService pizzaService;

	public ChefCookingServiceWorker() {
		super(new WorkerMeta("MakingPizza", "OrderPizzaService"));<1>
	}

	@Override
	@BusinessLocalTransactional <2>
	public LocalTransactionStepDefinition onStart(OrderPizzaPendingEvent orderPizzaPendingEvent) { <3>
		return LocalTransactionStepDefinition.builder().in(orderPizzaPendingEvent)<4>
				.blow(Stream.of(new BakingPizzaPendingEvent(orderPizzaPendingEvent.getCartID()))).meta(this.meta) <5>
				.build();
	}

	@Override
	@SwitchBusinessLocalTransactional <6>
	public LocalTransactionStepDefinition onNext(OrderPizzaCookedEvent orderPizzaCookedEvent) {

		OrderPizzaReadyForShipmentCommand cmd = null;
		if (pizzaService != null) {

			ToDilever b = new ToDilever("Some address", pizzaService.getOrders().get(orderPizzaCookedEvent.getCartId())
					.getPizzas().stream().map(Pizza::getName).collect(Collectors.toList()));
			cmd = new OrderPizzaReadyForShipmentCommand("deliver-pizza", "", b, "shippement-service");
		}
		return LocalTransactionStepDefinition.builder().in(orderPizzaCookedEvent)
				.blow(Stream.of(new OrderPizzaReadyEvent(orderPizzaCookedEvent.getCartId()))).<7>
				send(Stream.of(cmd)) <8>
				.meta(this.meta).build();
	}

	@Override
	@RollBackBusinessLocalTransactional <9>
	public LocalTransactionStepDefinition onError(ErrorLocalOccured errorLocalOccured) { <10>
		return LocalTransactionStepDefinition.builder().in(errorLocalOccured).meta(this.meta).build();
	}
}

----
<1> worker Meta data, contains the unique name **MakingPizza** of the local Transaction, it allows to identify it, also it allows to register it in the global transaction "OrderPizzaService"
<2> Transaction demarcation: start a new local transaction by listening to an event
<3> listen on an event of type OrderPizzaPendingEvent
<4> allow the Local Transaction StepDefinition to consume the event
<5> pass the meta data reference to the local Transaction StepDefinition
<6> transaction demarcation: Commit and close Local Transaction by listening to an event
<7> trigger an event stream
<8> send a command stream
<9> transaction demarcation: rollBack a Business LocalTransaction by listening to an event of type ErrorLocalOccured
<10> listen on an event of type ErrorLocalOccured
====

[IMPORTANT]
====
* a local transaction can monitor one or more local transactions
* a local transaction can only be registered to a single local transaction or global transaction through the metaWorker
* a local transaction cannot be committed, only if all of its children are committed 
====

== Compensating transaction (rollback)

the rollback phase of a business transaction begins when: 

* if one of the BFM workers fire an exception using its local or global pipeline builder (LocalTransactionStepDefinition or GlobalTransactionStepDefinition).
* the worker defines ** in the same pipeline builder ** a rollback policy by catching this exception:
   ** a rollback policy consists of mapping this exception to an event.
   ** a rollback policy can define a global or local compensation scope
   ** if the scope of compensation is global, the Orchestrator (realm manager) of the global transaction sends a message to all members (ambassadors), to suspend all transactions (global or local) and prepare them for a possible rollback . in this case The BFM (business flow model) instances accept only a commands dedicated for compensation or execute methods annotated with @RollBackBusinessLocalTransactional
   ** if the scope of compensation is local, a global transaction may have another chance to recover.

====
[source, java]
----
@Override
	@BusinessLocalTransactional
	public LocalTransactionStepDefinition onStart(DeliveryBillArrivedEvent deliveryBillArrivedEvent) {
		return LocalTransactionStepDefinition.builder().in(deliveryBillArrivedEvent)
				.blow(Stream.of(new DeliveryBillPayed())).receive(Bill.class, x -> {  <1>
					System.out.println(x.toString());
					if (x.getPrice() > 2) {
                     throw new ExpensiveException("pizza is too much expensive");  <2>
					}
				})
				 .compensateWhen(Propagation.GLOBAL,Stream.of(new PizzaRejectedEvent ()),DelayException.class, ExpensiveException.class) <3>
				.receive(Bill.class, (x, y) -> log.info("linking object {} with gtx {}", y, x)).meta(this.meta).build();

	}
	
	@Override
	@RollBackBusinessLocalTransactional
	
	public LocalTransactionStepDefinition onError(PizzaRejectedEvent pizzaRejectedEvent) { <4>
		return LocalTransactionStepDefinition.builder().in(pizzaRejectedEvent).meta(this.meta).build();
	}
	
----
<1> receives a command of type Bill.java
<2> under certain conditions you can raise an exception
<3> defines rollback policy which consists of mapping one or more exceptions to an event stream and indicating the scope of propagation.
<4> start a rollback pipeline by listening on the PizzaRejectedEvent
====

[WARNING]
====
* Not all exceptions raised within your application are captured by kermoss to start a rollback (compensating a business transaction).
* an exception should be triggered and captured by the same pipeline builder ** LocalTransactionStepDefinition ** or ** GlobalTransactionStepDefinition ** 
====

[TIP]
====
.Best practice
* always remember to create a service that you can inject into your BFM worker (Global or local), then call the method of this service containing the logic that raises an exception from the pipeline operators ** LocalTransactionStepDefinition ** or ** GlobalTransactionStepDefinition **
* in general the two operators recieve and process are sufficient to wrap the logic of an exception
    
====

== Synchronization

As explained previously, kermoss always promotes communication between its components in asynchronous mode and driven by messages, however in certain situations, you will have to condition the progress of your transaction by the availability of one or more business services, for example in the case of pizzashop microservice could only start its global transaction if the market service is up & running.

To synchronize the progress of your global transaction with the availability of one or more business services, the pipeline builder GlobalTransactionStepDefinition offers the operator ** prepare ** to perform this feature.

====
[source , java]
----
@Override
    @BusinessGlobalTransactional
    public GlobalTransactionStepDefinition onStart(OrderPizzaReceivedEvent orderPizzaReceivedEvent) {
        Need need = new Need(Arrays.asList("Tomatos", "mozzarella cheese", "meat"));
        CallMarketCommand cmd = new CallMarketCommand("call-market", "",
                need, "market-service"); <1>
       return GlobalTransactionStepDefinition.builder()
                .in(orderPizzaReceivedEvent)
                .meta(this.meta)
                .process(Optional.empty())
                .prepare(Stream.of(cmd)) <2>
                .blow(Stream.of(new OrderPizzaPendingEvent(orderPizzaReceivedEvent.getCartId())))
                .attach(gtx -> System.out.println("Attaching external process with gtx : " + gtx + " to OrderPizzaStateWorker"))
                .build();
    }
----
<1> create a command that you want to send to the remote BFM of the microservice Market as part of the synchronization protocol
<2> call the operator ** prepare ** to complete the synchronization
====

[TIP]
====
When you perform a synchronization with another microservice, it also allows to create a new BFM instance (ambassador) in this micorservice 
====
